{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\dev\\python\\lib\\site-packages\\tqdm\\auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import tensorflow_datasets as tfds\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from keras import layers,optimizers,losses\n",
    "\n",
    "physical_devices = tf.config.list_physical_devices(\"gPU\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<TakeDataset element_spec=TensorSpec(shape=(None, 28, 28, 1), dtype=tf.float32, name=None)>\n"
     ]
    }
   ],
   "source": [
    "\n",
    "(ds_train, _),infos=tfds.load(\n",
    "    name=\"mnist\",\n",
    "    split=[\"train\",\"test\"],\n",
    "    shuffle_files=True,\n",
    "    with_info=True ,  \n",
    "    as_supervised=False\n",
    ")\n",
    "\n",
    "def normalize_to_normal(x):\n",
    "    return 255*(x-1)/2\n",
    "\n",
    "def normalize_data(data):\n",
    "    return tf.cast(2*(data[\"image\"]/255)-1,tf.float32)\n",
    "\n",
    "ds_train=ds_train.map(normalize_data,num_parallel_calls=tf.data.AUTOTUNE)\n",
    "ds_train=ds_train.cache()\n",
    "ds_train=ds_train.shuffle(infos.splits[\"train\"].num_examples)#60,000\n",
    "ds_train=ds_train.batch(batch_size=64)\n",
    "ds_train=ds_train.prefetch(tf.data.AUTOTUNE)\n",
    "\n",
    "print(ds_train.take(0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generator Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_1 (InputLayer)        [(None, 128)]             0         \n",
      "                                                                 \n",
      " linear (Dense)              (None, 12544)             1618176   \n",
      "                                                                 \n",
      " reshape (Reshape)           (None, 7, 7, 256)         0         \n",
      "                                                                 \n",
      " TPCNN_1 (CNNTranspose)      (None, 7, 7, 128)         819712    \n",
      "                                                                 \n",
      " TPCNN_2 (CNNTranspose)      (None, 14, 14, 64)        205056    \n",
      "                                                                 \n",
      " output (Conv2DTranspose)    (None, 28, 28, 1)         577       \n",
      "                                                                 \n",
      " tf.math.tanh (TFOpLambda)   (None, 28, 28, 1)         0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 2,643,521\n",
      "Trainable params: 2,643,137\n",
      "Non-trainable params: 384\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "class CNNTranspose(layers.Layer):\n",
    "    def __init__(self,channels,filter_size,stride=2,padding=\"same\",name=None):\n",
    "        super(CNNTranspose,self).__init__(name=name)\n",
    "        self.cnt=layers.Conv2DTranspose(channels,filter_size,stride,padding,use_bias=False)\n",
    "        self.bn=layers.BatchNormalization()\n",
    "    def call(self,inputs,training=False):\n",
    "        x=self.cnt(inputs)\n",
    "        x=self.bn(x,training=training)\n",
    "        return tf.nn.relu(x)\n",
    "\n",
    "\n",
    "\n",
    "class Generator(keras.Model):\n",
    "    seed_dim=128\n",
    "    def __init__(self):\n",
    "        super(Generator,self).__init__()\n",
    "        self.linear=layers.Dense(7*7*256,name=\"linear\")\n",
    "        self.tcn1=CNNTranspose(128,5,stride=1,name='TPCNN_1')\n",
    "        self.tcn2=CNNTranspose(64,5,stride=2,name=\"TPCNN_2\")\n",
    "        self.output_layer=layers.Conv2DTranspose(1,3,2,\"same\",name='output')\n",
    "    def call(self,inputs,training=False):\n",
    "        x=self.linear(inputs)\n",
    "        x=layers.Reshape((7,7,256))(x)\n",
    "        x=self.tcn1(x,training=training)\n",
    "        x=self.tcn2(x,training=training)\n",
    "        x=self.output_layer(x)\n",
    "        return tf.keras.activations.tanh(x)\n",
    "    def architecture(self):\n",
    "        x=keras.Input((128))\n",
    "        model=tf.keras.Model(inputs=[x],outputs=self.call(x))\n",
    "        return model.summary()\n",
    "    \n",
    "generator=Generator()\n",
    "generator.architecture()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Discriminator Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_2 (InputLayer)        [(None, 28, 28, 1)]       0         \n",
      "                                                                 \n",
      " Conv_1 (Conv2D)             (None, 14, 14, 64)        640       \n",
      "                                                                 \n",
      " tf.nn.leaky_relu (TFOpLambd  (None, 14, 14, 64)       0         \n",
      " a)                                                              \n",
      "                                                                 \n",
      " Conv_2 (CNN)                (None, 7, 7, 128)         205312    \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 6272)              0         \n",
      "                                                                 \n",
      " output (Dense)              (None, 1)                 6273      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 212,225\n",
      "Trainable params: 211,969\n",
      "Non-trainable params: 256\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "class CNN(layers.Layer):\n",
    "    def __init__(self,channels,filter_size,name=None):\n",
    "        super(CNN,self).__init__(name=name)\n",
    "        self.cnn=layers.Conv2D(channels,filter_size,strides=2,padding=\"same\",use_bias=False)\n",
    "        self.bn=layers.BatchNormalization()\n",
    "    def call(self,inputs,training=False):\n",
    "        x=self.cnn(inputs)\n",
    "        x=self.bn(x,training=training)\n",
    "        return tf.nn.leaky_relu(x)\n",
    "\n",
    "\n",
    "class Discriminator(keras.Model):\n",
    "    def __init__(self):\n",
    "        super(Discriminator,self).__init__()\n",
    "        self.cnn1=layers.Conv2D(64,3,2,padding=\"same\",name=\"Conv_1\")\n",
    "        self.cnn2=CNN(128,5,name=\"Conv_2\")\n",
    "        self.cnn3=CNN(256,5,name=\"Conv_1\")\n",
    "        self.output_layer=layers.Dense(1,'sigmoid',name=\"output\")\n",
    "    def call(self,inputs,training=False):\n",
    "        x=self.cnn1(inputs)\n",
    "        x=tf.nn.leaky_relu(x)\n",
    "        x=self.cnn2(x,training=training)\n",
    "        #x=self.cnn3(x,training=training)\n",
    "        x=layers.Flatten()(x)\n",
    "        x=self.output_layer(x)\n",
    "        return x\n",
    "    def architecture(self):\n",
    "        x=keras.Input((28,28,1))\n",
    "        model=tf.keras.Model(inputs=[x],outputs=self.call(x))\n",
    "        return model.summary()\n",
    "\n",
    "\n",
    "discriminator=Discriminator()\n",
    "discriminator.architecture()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train the Networks\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Optimizer and Loss Function\n",
    "\n",
    "* loss function : log(D(x))+log(1-D(G(z)))\n",
    "* Optimizer : Adam\n",
    "* learning rate :3e-4\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "gen_opt=optimizers.Adam(1e-4)\n",
    "disc_opt=optimizers.Adam(1e-4)\n",
    "loss_fn=losses.BinaryCrossentropy()\n",
    "num_epochs=50"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training loop\n",
    "* the Discriminator try to maximize the loss function\n",
    "* the Generator try to minimize log(1-D(G(Z))) or maximize log(D(G(x)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 938/938 [01:21<00:00, 11.49it/s]\n",
      "100%|██████████| 938/938 [01:12<00:00, 12.90it/s]\n",
      "100%|██████████| 938/938 [01:11<00:00, 13.13it/s]\n",
      "100%|██████████| 938/938 [01:10<00:00, 13.23it/s]\n",
      "100%|██████████| 938/938 [01:12<00:00, 12.90it/s]\n",
      "100%|██████████| 938/938 [01:13<00:00, 12.76it/s]\n",
      "100%|██████████| 938/938 [01:13<00:00, 12.80it/s]\n",
      "100%|██████████| 938/938 [01:12<00:00, 12.92it/s]\n",
      "100%|██████████| 938/938 [01:14<00:00, 12.66it/s]\n",
      " 29%|██▉       | 273/938 [00:21<00:53, 12.50it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32mc:\\dev\\compile\\python projects\\ai\\deeplearning\\GANS\\Mnist Gans\\Training.ipynb Cell 13\u001b[0m in \u001b[0;36m<cell line: 4>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/dev/compile/python%20projects/ai/deeplearning/GANS/Mnist%20Gans/Training.ipynb#X15sZmlsZQ%3D%3D?line=14'>15</a>\u001b[0m fake\u001b[39m=\u001b[39mgenerator(z,training\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m) \u001b[39m#G(z)\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/dev/compile/python%20projects/ai/deeplearning/GANS/Mnist%20Gans/Training.ipynb#X15sZmlsZQ%3D%3D?line=16'>17</a>\u001b[0m real_loss\u001b[39m=\u001b[39mloss_fn(tf\u001b[39m.\u001b[39mones(bach_size,\u001b[39m1\u001b[39m),discriminator(real,training\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)) \u001b[39m#log(D(x)) \u001b[39;00m\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/dev/compile/python%20projects/ai/deeplearning/GANS/Mnist%20Gans/Training.ipynb#X15sZmlsZQ%3D%3D?line=17'>18</a>\u001b[0m fake_loss\u001b[39m=\u001b[39mloss_fn(tf\u001b[39m.\u001b[39mzeros(bach_size,\u001b[39m1\u001b[39m),discriminator(fake,training\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m))\u001b[39m#log(1-D(G(Z)))\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/dev/compile/python%20projects/ai/deeplearning/GANS/Mnist%20Gans/Training.ipynb#X15sZmlsZQ%3D%3D?line=19'>20</a>\u001b[0m disc_loss\u001b[39m=\u001b[39mreal_loss\u001b[39m+\u001b[39mfake_loss\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/dev/compile/python%20projects/ai/deeplearning/GANS/Mnist%20Gans/Training.ipynb#X15sZmlsZQ%3D%3D?line=20'>21</a>\u001b[0m gen_loss\u001b[39m=\u001b[39mloss_fn(tf\u001b[39m.\u001b[39mones(bach_size,\u001b[39m1\u001b[39m),discriminator(fake))\n",
      "File \u001b[1;32mc:\\dev\\python\\lib\\site-packages\\keras\\utils\\traceback_utils.py:65\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     63\u001b[0m filtered_tb \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m     64\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m---> 65\u001b[0m     \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m     66\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m     67\u001b[0m     filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32mc:\\dev\\python\\lib\\site-packages\\keras\\engine\\training.py:557\u001b[0m, in \u001b[0;36mModel.__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    553\u001b[0m         \u001b[39msuper\u001b[39m()\u001b[39m.\u001b[39m\u001b[39m__call__\u001b[39m(inputs, \u001b[39m*\u001b[39mcopied_args, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mcopied_kwargs)\n\u001b[0;32m    555\u001b[0m     layout_map_lib\u001b[39m.\u001b[39m_map_subclass_model_variable(\u001b[39mself\u001b[39m, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_layout_map)\n\u001b[1;32m--> 557\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39msuper\u001b[39m()\u001b[39m.\u001b[39m\u001b[39m__call__\u001b[39m(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\dev\\python\\lib\\site-packages\\keras\\utils\\traceback_utils.py:65\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     63\u001b[0m filtered_tb \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m     64\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m---> 65\u001b[0m     \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m     66\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m     67\u001b[0m     filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32mc:\\dev\\python\\lib\\site-packages\\keras\\engine\\base_layer.py:1097\u001b[0m, in \u001b[0;36mLayer.__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1092\u001b[0m     inputs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_maybe_cast_inputs(inputs, input_list)\n\u001b[0;32m   1094\u001b[0m \u001b[39mwith\u001b[39;00m autocast_variable\u001b[39m.\u001b[39menable_auto_cast_variables(\n\u001b[0;32m   1095\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_compute_dtype_object\n\u001b[0;32m   1096\u001b[0m ):\n\u001b[1;32m-> 1097\u001b[0m     outputs \u001b[39m=\u001b[39m call_fn(inputs, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m   1099\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_activity_regularizer:\n\u001b[0;32m   1100\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_handle_activity_regularization(inputs, outputs)\n",
      "File \u001b[1;32mc:\\dev\\python\\lib\\site-packages\\keras\\utils\\traceback_utils.py:96\u001b[0m, in \u001b[0;36minject_argument_info_in_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     94\u001b[0m bound_signature \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m     95\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m---> 96\u001b[0m     \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m     97\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m     98\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mhasattr\u001b[39m(e, \u001b[39m\"\u001b[39m\u001b[39m_keras_call_info_injected\u001b[39m\u001b[39m\"\u001b[39m):\n\u001b[0;32m     99\u001b[0m         \u001b[39m# Only inject info for the innermost failing call\u001b[39;00m\n",
      "\u001b[1;32mc:\\dev\\compile\\python projects\\ai\\deeplearning\\GANS\\Mnist Gans\\Training.ipynb Cell 13\u001b[0m in \u001b[0;36mDiscriminator.call\u001b[1;34m(self, inputs, training)\u001b[0m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/dev/compile/python%20projects/ai/deeplearning/GANS/Mnist%20Gans/Training.ipynb#X15sZmlsZQ%3D%3D?line=22'>23</a>\u001b[0m \u001b[39m#x=self.cnn3(x,training=training)\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/dev/compile/python%20projects/ai/deeplearning/GANS/Mnist%20Gans/Training.ipynb#X15sZmlsZQ%3D%3D?line=23'>24</a>\u001b[0m x\u001b[39m=\u001b[39mlayers\u001b[39m.\u001b[39mFlatten()(x)\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/dev/compile/python%20projects/ai/deeplearning/GANS/Mnist%20Gans/Training.ipynb#X15sZmlsZQ%3D%3D?line=24'>25</a>\u001b[0m x\u001b[39m=\u001b[39m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49moutput_layer(x)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/dev/compile/python%20projects/ai/deeplearning/GANS/Mnist%20Gans/Training.ipynb#X15sZmlsZQ%3D%3D?line=25'>26</a>\u001b[0m \u001b[39mreturn\u001b[39;00m x\n",
      "File \u001b[1;32mc:\\dev\\python\\lib\\site-packages\\keras\\utils\\traceback_utils.py:65\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     63\u001b[0m filtered_tb \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m     64\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m---> 65\u001b[0m     \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m     66\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m     67\u001b[0m     filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32mc:\\dev\\python\\lib\\site-packages\\keras\\engine\\base_layer.py:1097\u001b[0m, in \u001b[0;36mLayer.__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1092\u001b[0m     inputs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_maybe_cast_inputs(inputs, input_list)\n\u001b[0;32m   1094\u001b[0m \u001b[39mwith\u001b[39;00m autocast_variable\u001b[39m.\u001b[39menable_auto_cast_variables(\n\u001b[0;32m   1095\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_compute_dtype_object\n\u001b[0;32m   1096\u001b[0m ):\n\u001b[1;32m-> 1097\u001b[0m     outputs \u001b[39m=\u001b[39m call_fn(inputs, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m   1099\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_activity_regularizer:\n\u001b[0;32m   1100\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_handle_activity_regularization(inputs, outputs)\n",
      "File \u001b[1;32mc:\\dev\\python\\lib\\site-packages\\keras\\utils\\traceback_utils.py:96\u001b[0m, in \u001b[0;36minject_argument_info_in_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     94\u001b[0m bound_signature \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m     95\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m---> 96\u001b[0m     \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m     97\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m     98\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mhasattr\u001b[39m(e, \u001b[39m\"\u001b[39m\u001b[39m_keras_call_info_injected\u001b[39m\u001b[39m\"\u001b[39m):\n\u001b[0;32m     99\u001b[0m         \u001b[39m# Only inject info for the innermost failing call\u001b[39;00m\n",
      "File \u001b[1;32mc:\\dev\\python\\lib\\site-packages\\keras\\layers\\core\\dense.py:252\u001b[0m, in \u001b[0;36mDense.call\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m    249\u001b[0m         outputs\u001b[39m.\u001b[39mset_shape(output_shape)\n\u001b[0;32m    251\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39muse_bias:\n\u001b[1;32m--> 252\u001b[0m     outputs \u001b[39m=\u001b[39m tf\u001b[39m.\u001b[39;49mnn\u001b[39m.\u001b[39;49mbias_add(outputs, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mbias)\n\u001b[0;32m    254\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mactivation \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m    255\u001b[0m     outputs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mactivation(outputs)\n",
      "File \u001b[1;32mc:\\dev\\python\\lib\\site-packages\\tensorflow\\python\\util\\traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    148\u001b[0m filtered_tb \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m    149\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m--> 150\u001b[0m   \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m    151\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m    152\u001b[0m   filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32mc:\\dev\\python\\lib\\site-packages\\tensorflow\\python\\util\\dispatch.py:1176\u001b[0m, in \u001b[0;36madd_dispatch_support.<locals>.decorator.<locals>.op_dispatch_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m   1174\u001b[0m \u001b[39m# Fallback dispatch system (dispatch v1):\u001b[39;00m\n\u001b[0;32m   1175\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m-> 1176\u001b[0m   \u001b[39mreturn\u001b[39;00m dispatch_target(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m   1177\u001b[0m \u001b[39mexcept\u001b[39;00m (\u001b[39mTypeError\u001b[39;00m, \u001b[39mValueError\u001b[39;00m):\n\u001b[0;32m   1178\u001b[0m   \u001b[39m# Note: convert_to_eager_tensor currently raises a ValueError, not a\u001b[39;00m\n\u001b[0;32m   1179\u001b[0m   \u001b[39m# TypeError, when given unexpected types.  So we need to catch both.\u001b[39;00m\n\u001b[0;32m   1180\u001b[0m   result \u001b[39m=\u001b[39m dispatch(op_dispatch_handler, args, kwargs)\n",
      "File \u001b[1;32mc:\\dev\\python\\lib\\site-packages\\tensorflow\\python\\ops\\nn_ops.py:3554\u001b[0m, in \u001b[0;36mbias_add\u001b[1;34m(value, bias, data_format, name)\u001b[0m\n\u001b[0;32m   3551\u001b[0m   value \u001b[39m=\u001b[39m ops\u001b[39m.\u001b[39mconvert_to_tensor(value, name\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39minput\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m   3552\u001b[0m   bias \u001b[39m=\u001b[39m ops\u001b[39m.\u001b[39mconvert_to_tensor(bias, dtype\u001b[39m=\u001b[39mvalue\u001b[39m.\u001b[39mdtype, name\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mbias\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m-> 3554\u001b[0m \u001b[39mreturn\u001b[39;00m gen_nn_ops\u001b[39m.\u001b[39;49mbias_add(value, bias, data_format\u001b[39m=\u001b[39;49mdata_format, name\u001b[39m=\u001b[39;49mname)\n",
      "File \u001b[1;32mc:\\dev\\python\\lib\\site-packages\\tensorflow\\python\\ops\\gen_nn_ops.py:849\u001b[0m, in \u001b[0;36mbias_add\u001b[1;34m(value, bias, data_format, name)\u001b[0m\n\u001b[0;32m    847\u001b[0m \u001b[39mif\u001b[39;00m tld\u001b[39m.\u001b[39mis_eager:\n\u001b[0;32m    848\u001b[0m   \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m--> 849\u001b[0m     _result \u001b[39m=\u001b[39m pywrap_tfe\u001b[39m.\u001b[39;49mTFE_Py_FastPathExecute(\n\u001b[0;32m    850\u001b[0m       _ctx, \u001b[39m\"\u001b[39;49m\u001b[39mBiasAdd\u001b[39;49m\u001b[39m\"\u001b[39;49m, name, value, bias, \u001b[39m\"\u001b[39;49m\u001b[39mdata_format\u001b[39;49m\u001b[39m\"\u001b[39;49m, data_format)\n\u001b[0;32m    851\u001b[0m     \u001b[39mreturn\u001b[39;00m _result\n\u001b[0;32m    852\u001b[0m   \u001b[39mexcept\u001b[39;00m _core\u001b[39m.\u001b[39m_NotOkStatusException \u001b[39mas\u001b[39;00m e:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import tqdm\n",
    "import os\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    for idx,real in enumerate(tqdm.tqdm(ds_train)):\n",
    "        bach_size=real.shape[0]\n",
    "        z=tf.random.normal([bach_size,Generator.seed_dim])  #random noise\n",
    "        \n",
    "\n",
    "        \n",
    "\n",
    "        #train the \n",
    "        \n",
    "        with tf.GradientTape() as gen_tape, tf.GradientTape() as disc_tape : \n",
    "            fake=generator(z,training=True) #G(z)\n",
    "\n",
    "            real_loss=loss_fn(tf.ones(bach_size,1),discriminator(real,training=True)) #log(D(x)) \n",
    "            fake_loss=loss_fn(tf.zeros(bach_size,1),discriminator(fake,training=True))#log(1-D(G(Z)))\n",
    "\n",
    "            disc_loss=real_loss+fake_loss\n",
    "            gen_loss=loss_fn(tf.ones(bach_size,1),discriminator(fake))\n",
    "        \n",
    "        grads_gen=gen_tape.gradient(gen_loss,generator.trainable_variables)\n",
    "        gen_opt.apply_gradients(zip(grads_gen,generator.trainable_variables))\n",
    "        grads_disc=disc_tape.gradient(disc_loss,discriminator.trainable_variables)\n",
    "        disc_opt.apply_gradients(zip(grads_disc,discriminator.trainable_variables))\n",
    "        generated_image=generator(z,training=False)\n",
    "        if idx % 100 ==0:\n",
    "            img=tf.keras.preprocessing.image.array_to_img(normalize_to_normal(generated_image[0]))\n",
    "            img.save(f\"generated_images/generated_img{epoch}_{idx}_.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import tqdm\n",
    "# import os\n",
    "\n",
    "# for epoch in range(num_epochs):\n",
    "#     for idx,real in enumerate(tqdm.tqdm(ds_train)):\n",
    "#         bach_size=real.shape[0]\n",
    "#         z=tf.random.normal((bach_size,Generator.seed_dim))  #random noise\n",
    "#         fake=generator(z) #G(z)\n",
    "\n",
    "#         if idx % 100 ==0:\n",
    "#             img=tf.keras.preprocessing.image.array_to_img(normalize_to_normal(fake[0]))\n",
    "#             img.save(f\"generated_images/generated_img{epoch}_{idx}_.png\")\n",
    "\n",
    "#         #train the discriminator\n",
    "#         with tf.GradientTape() as disc_tape: \n",
    "#             real_loss=loss_fn(tf.ones(bach_size,1),discriminator(real)) #log(D(x)) \n",
    "#             fake_loss=loss_fn(tf.zeros(bach_size,1),discriminator(fake))#log(1-D(G(Z)))\n",
    "#             disc_loss=real_loss+fake_loss\n",
    "        \n",
    "#         grads=disc_tape.gradient(disc_loss,discriminator.trainable_weights)\n",
    "#         disc_opt.apply_gradients(zip(grads,discriminator.trainable_weights))\n",
    "        \n",
    "#         #train the generator \n",
    "#         with tf.GradientTape() as gen_tape:\n",
    "#             Gz=generator(z)\n",
    "#             gen_loss=loss_fn(tf.ones(bach_size,1),discriminator(Gz))\n",
    "        \n",
    "#         grads=gen_tape.gradient(gen_loss,generator.trainable_weights)\n",
    "#         gen_opt.apply_gradients(zip(grads,generator.trainable_weights))\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "noise=np.random.rand(64,128)\n",
    "plt.style.use(\"grayscale\")\n",
    "fakes=generator.predict(z)\n",
    "plt.imshow(fake[3])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.7 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "f3663913924b1daa3d8d3926798e99031b125700758b9d2e89fd61fec1c9e6b0"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
